{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "In this chapter, we’ll illustrate the basics of multi-label classification with an example. But first, we want to distinguish between two kinds of classification, multi-class classification and multi-label classification.\n",
    "## Multi-class Classification \n",
    "The model will categorize/classify the input image into one of several classes (thus, multi-class), i.e.,the input image belongs to one and only one class out of several. For example, let's say the image has a dominant object  of an airplane in the foreground  and perhaps  smaller objects (say, trucks) in the background. This image will be classified into the single category of airplane. \n",
    "\n",
    "\n",
    "\n",
    "![desert](assets/desert+mountains-label-desert.png)\n",
    "\n",
    "For computing the loss for multi-class classification, it's convenient to use the torch.nn.CrossEntropyLoss class which combines nn.LogSoftmax() and nn.NLLLoss() into one single class.\n",
    "\n",
    "## Multi-label Classification \n",
    "“Multi-label” classification means that each image can belong to any\n",
    "number of the specified classes, including zero (background). So multi-label\n",
    "classification can be understood as a series of binary classifications per class.\n",
    "Is the image in class A – yes or no? \n",
    "Is the same image in class B – yes or no?\n",
    "And so on.\n",
    "This is how we end up with multiple labels/classes for a single image.\n",
    "\n",
    "![desert+mountains](assets/desert+mountains-label-desert+mountains.png)\n",
    "\n",
    "For computing the loss for multi-label classification, it's convenient to use the torch.nn.BCEWithLogitsLoss class which combines a Sigmoid layer and the BCELoss (Binary Cross Entropy Loss) in one single class. By combining the operations into one layer, we take advantage of numerical stability inherent in these combined operations (and this is well documented).\n",
    "\n",
    "We note that, in both types of classifications, the rest of the network layers are unchanged (only the loss function at the head of the network changes). "
   ]
  },
  {
   "source": [
    "# Dataset Download\n",
    "\n",
    "The dataset is available at http://www.lamda.nju.edu.cn/data_MIMLimage.ashx\n",
    "As you would expect, the dataset has two parts; the images of the scenes and the corresponding labels:\n",
    "(1)\t\"original\" part has the 2000 images. An image can belong to one or more classes.  The classes happen to be ['desert', 'mountains', 'sea', 'sunset', 'trees']\n",
    "(2) \"processed\" part has the labels\n",
    "\n",
    "You should have a folder called `original_images` containing the 2000 images and a file called `miml data.mat` containing the labels.\n",
    "\n",
    "Note, do the steps below __only once__.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "K \n",
      "Extracting  original_images/1758.jpg                                    92  OK \n",
      "Extracting  original_images/1759.jpg                                    92  OK \n",
      "Extracting  original_images/1760.jpg                                    92  OK \n",
      "Extracting  original_images/1761.jpg                                    92  OK \n",
      "Extracting  original_images/1762.jpg                                    92  OK \n",
      "Extracting  original_images/1763.jpg                                    92  OK \n",
      "Extracting  original_images/1764.jpg                                    92  OK \n",
      "Extracting  original_images/1765.jpg                                    93  OK \n",
      "Extracting  original_images/1766.jpg                                    93  OK \n",
      "Extracting  original_images/1767.jpg                                    93  OK \n",
      "Extracting  original_images/1768.jpg                                    93  OK \n",
      "Extracting  original_images/1769.jpg                                    93  OK \n",
      "Extracting  original_images/1770.jpg                                    93  OK \n",
      "Extracting  original_images/1771.jpg                                    93  OK \n",
      "Extracting  original_images/1772.jpg                                    93  OK \n",
      "Extracting  original_images/1773.jpg                                    93  OK \n",
      "Extracting  original_images/1774.jpg                                    93  OK \n",
      "Extracting  original_images/1775.jpg                                    94  OK \n",
      "Extracting  original_images/1776.jpg                                    94  OK \n",
      "Extracting  original_images/1777.jpg                                    94  OK \n",
      "Extracting  original_images/1778.jpg                                    94  OK \n",
      "Extracting  original_images/1779.jpg                                    94  OK \n",
      "Extracting  original_images/1780.jpg                                    94  OK \n",
      "Extracting  original_images/1781.jpg                                    94  OK \n",
      "Extracting  original_images/1782.jpg                                    94  OK \n",
      "Extracting  original_images/1783.jpg                                    95  OK \n",
      "Extracting  original_images/1784.jpg                                    95  OK \n",
      "Extracting  original_images/1785.jpg                                    95  OK \n",
      "Extracting  original_images/1786.jpg                                    95  OK \n",
      "Extracting  original_images/1787.jpg                                    95  OK \n",
      "Extracting  original_images/1788.jpg                                    95  OK \n",
      "Extracting  original_images/1789.jpg                                    95  OK \n",
      "Extracting  original_images/1790.jpg                                    95  OK \n",
      "Extracting  original_images/1791.jpg                                    95  OK \n",
      "Extracting  original_images/1792.jpg                                    95  OK \n",
      "Extracting  original_images/1793.jpg                                    95  OK \n",
      "Extracting  original_images/1794.jpg                                    95  OK \n",
      "Extracting  original_images/1795.jpg                                    95  OK \n",
      "Extracting  original_images/1796.jpg                                    95  OK \n",
      "Extracting  original_images/1797.jpg                                    95  OK \n",
      "Extracting  original_images/1798.jpg                                    95  OK \n",
      "Extracting  original_images/1799.jpg                                    95  OK \n",
      "Extracting  original_images/1800.jpg                                    95  OK \n",
      "Extracting  original_images/1801.jpg                                    95  OK \n",
      "Extracting  original_images/1802.jpg                                    95  OK \n",
      "Extracting  original_images/1803.jpg                                    95  OK \n",
      "Extracting  original_images/1804.jpg                                    95  OK \n",
      "Extracting  original_images/1805.jpg                                    95  OK \n",
      "Extracting  original_images/1806.jpg                                    95  OK \n",
      "Extracting  original_images/1807.jpg                                    95  OK \n",
      "Extracting  original_images/1808.jpg                                    95  OK \n",
      "Extracting  original_images/1809.jpg                                    95  OK \n",
      "Extracting  original_images/1810.jpg                                    95  OK \n",
      "Extracting  original_images/1811.jpg                                    95  OK \n",
      "Extracting  original_images/1812.jpg                                    95  OK \n",
      "Extracting  original_images/1813.jpg                                    95  OK \n",
      "Extracting  original_images/1814.jpg                                    95  OK \n",
      "Extracting  original_images/1815.jpg                                    95  OK \n",
      "Extracting  original_images/1816.jpg                                    95  OK \n",
      "Extracting  original_images/1817.jpg                                    95  OK \n",
      "Extracting  original_images/1818.jpg                                    95  OK \n",
      "Extracting  original_images/1819.jpg                                    95  OK \n",
      "Extracting  original_images/1820.jpg                                    95  OK \n",
      "Extracting  original_images/1821.jpg                                    95  OK \n",
      "Extracting  original_images/1822.jpg                                    95  OK \n",
      "Extracting  original_images/1823.jpg                                    96  OK \n",
      "Extracting  original_images/1824.jpg                                    96  OK \n",
      "Extracting  original_images/1825.jpg                                    96  OK \n",
      "Extracting  original_images/1826.jpg                                    96  OK \n",
      "Extracting  original_images/1827.jpg                                    96  OK \n",
      "Extracting  original_images/1828.jpg                                    96  OK \n",
      "Extracting  original_images/1829.jpg                                    96  OK \n",
      "Extracting  original_images/1830.jpg                                    96  OK \n",
      "Extracting  original_images/1831.jpg                                    96  OK \n",
      "Extracting  original_images/1832.jpg                                    96  OK \n",
      "Extracting  original_images/1833.jpg                                    96  OK \n",
      "Extracting  original_images/1834.jpg                                    96  OK \n",
      "Extracting  original_images/1835.jpg                                    96  OK \n",
      "Extracting  original_images/1836.jpg                                    96  OK \n",
      "Extracting  original_images/1837.jpg                                    96  OK \n",
      "Extracting  original_images/1838.jpg                                    96  OK \n",
      "Extracting  original_images/1839.jpg                                    96  OK \n",
      "Extracting  original_images/1840.jpg                                    96  OK \n",
      "Extracting  original_images/1841.jpg                                    96  OK \n",
      "Extracting  original_images/1842.jpg                                    96  OK \n",
      "Extracting  original_images/1843.jpg                                    96  OK \n",
      "Extracting  original_images/1844.jpg                                    96  OK \n",
      "Extracting  original_images/1845.jpg                                    96  OK \n",
      "Extracting  original_images/1846.jpg                                    96  OK \n",
      "Extracting  original_images/1847.jpg                                    96  OK \n",
      "Extracting  original_images/1848.jpg                                    96  OK \n",
      "Extracting  original_images/1849.jpg                                    96  OK \n",
      "Extracting  original_images/1850.jpg                                    96  OK \n",
      "Extracting  original_images/1851.jpg                                    96  OK \n",
      "Extracting  original_images/1852.jpg                                    96  OK \n",
      "Extracting  original_images/1853.jpg                                    96  OK \n",
      "Extracting  original_images/1854.jpg                                    96  OK \n",
      "Extracting  original_images/1855.jpg                                    96  OK \n",
      "Extracting  original_images/1856.jpg                                    96  OK \n",
      "Extracting  original_images/1857.jpg                                    96  OK \n",
      "Extracting  original_images/1858.jpg                                    96  OK \n",
      "Extracting  original_images/1859.jpg                                    96  OK \n",
      "Extracting  original_images/1860.jpg                                    96  OK \n",
      "Extracting  original_images/1861.jpg                                    96  OK \n",
      "Extracting  original_images/1862.jpg                                    96  OK \n",
      "Extracting  original_images/1863.jpg                                    96  OK \n",
      "Extracting  original_images/1864.jpg                                    96  OK \n",
      "Extracting  original_images/1865.jpg                                    96  OK \n",
      "Extracting  original_images/1866.jpg                                    96  OK \n",
      "Extracting  original_images/1867.jpg                                    96  OK \n",
      "Extracting  original_images/1868.jpg                                    96  OK \n",
      "Extracting  original_images/1869.jpg                                    96  OK \n",
      "Extracting  original_images/1870.jpg                                    96  OK \n",
      "Extracting  original_images/1871.jpg                                    96  OK \n",
      "Extracting  original_images/1872.jpg                                    97  OK \n",
      "Extracting  original_images/1873.jpg                                    97  OK \n",
      "Extracting  original_images/1874.jpg                                    97  OK \n",
      "Extracting  original_images/1875.jpg                                    97  OK \n",
      "Extracting  original_images/1876.jpg                                    97  OK \n",
      "Extracting  original_images/1877.jpg                                    97  OK \n",
      "Extracting  original_images/1878.jpg                                    97  OK \n",
      "Extracting  original_images/1879.jpg                                    97  OK \n",
      "Extracting  original_images/1880.jpg                                    97  OK \n",
      "Extracting  original_images/1881.jpg                                    97  OK \n",
      "Extracting  original_images/1882.jpg                                    97  OK \n",
      "Extracting  original_images/1883.jpg                                    97  OK \n",
      "Extracting  original_images/1884.jpg                                    97  OK \n",
      "Extracting  original_images/1885.jpg                                    97  OK \n",
      "Extracting  original_images/1886.jpg                                    97  OK \n",
      "Extracting  original_images/1887.jpg                                    97  OK \n",
      "Extracting  original_images/1888.jpg                                    97  OK \n",
      "Extracting  original_images/1889.jpg                                    97  OK \n",
      "Extracting  original_images/1890.jpg                                    97  OK \n",
      "Extracting  original_images/1891.jpg                                    97  OK \n",
      "Extracting  original_images/1892.jpg                                    97  OK \n",
      "Extracting  original_images/1893.jpg                                    97  OK \n",
      "Extracting  original_images/1894.jpg                                    97  OK \n",
      "Extracting  original_images/1895.jpg                                    97  OK \n",
      "Extracting  original_images/1896.jpg                                    97  OK \n",
      "Extracting  original_images/1897.jpg                                    97  OK \n",
      "Extracting  original_images/1898.jpg                                    97  OK \n",
      "Extracting  original_images/1899.jpg                                    97  OK \n",
      "Extracting  original_images/1900.jpg                                    97  OK \n",
      "Extracting  original_images/1901.jpg                                    97  OK \n",
      "Extracting  original_images/1902.jpg                                    97  OK \n",
      "Extracting  original_images/1903.jpg                                    97  OK \n",
      "Extracting  original_images/1904.jpg                                    97  OK \n",
      "Extracting  original_images/1905.jpg                                    97  OK \n",
      "Extracting  original_images/1906.jpg                                    97  OK \n",
      "Extracting  original_images/1907.jpg                                    97  OK \n",
      "Extracting  original_images/1908.jpg                                    97  OK \n",
      "Extracting  original_images/1909.jpg                                    97  OK \n",
      "Extracting  original_images/1910.jpg                                    97  OK \n",
      "Extracting  original_images/1911.jpg                                    97  OK \n",
      "Extracting  original_images/1912.jpg                                    97  OK \n",
      "Extracting  original_images/1913.jpg                                    97  OK \n",
      "Extracting  original_images/1914.jpg                                    97  OK \n",
      "Extracting  original_images/1915.jpg                                    97  OK \n",
      "Extracting  original_images/1916.jpg                                    97  OK \n",
      "Extracting  original_images/1917.jpg                                    97  OK \n",
      "Extracting  original_images/1918.jpg                                    97  OK \n",
      "Extracting  original_images/1919.jpg                                    97  OK \n",
      "Extracting  original_images/1920.jpg                                    97  OK \n",
      "Extracting  original_images/1921.jpg                                    97  OK \n",
      "Extracting  original_images/1922.jpg                                    97  OK \n",
      "Extracting  original_images/1923.jpg                                    98  OK \n",
      "Extracting  original_images/1924.jpg                                    98  OK \n",
      "Extracting  original_images/1925.jpg                                    98  OK \n",
      "Extracting  original_images/1926.jpg                                    98  OK \n",
      "Extracting  original_images/1927.jpg                                    98  OK \n",
      "Extracting  original_images/1928.jpg                                    98  OK \n",
      "Extracting  original_images/1929.jpg                                    98  OK \n",
      "Extracting  original_images/1930.jpg                                    98  OK \n",
      "Extracting  original_images/1931.jpg                                    98  OK \n",
      "Extracting  original_images/1932.jpg                                    98  OK \n",
      "Extracting  original_images/1933.jpg                                    98  OK \n",
      "Extracting  original_images/1934.jpg                                    98  OK \n",
      "Extracting  original_images/1935.jpg                                    98  OK \n",
      "Extracting  original_images/1936.jpg                                    98  OK \n",
      "Extracting  original_images/1937.jpg                                    98  OK \n",
      "Extracting  original_images/1938.jpg                                    98  OK \n",
      "Extracting  original_images/1939.jpg                                    98  OK \n",
      "Extracting  original_images/1940.jpg                                    98  OK \n",
      "Extracting  original_images/1941.jpg                                    98  OK \n",
      "Extracting  original_images/1942.jpg                                    98  OK \n",
      "Extracting  original_images/1943.jpg                                    98  OK \n",
      "Extracting  original_images/1944.jpg                                    98  OK \n",
      "Extracting  original_images/1945.jpg                                    98  OK \n",
      "Extracting  original_images/1946.jpg                                    98  OK \n",
      "Extracting  original_images/1947.jpg                                    98  OK \n",
      "Extracting  original_images/1948.jpg                                    98  OK \n",
      "Extracting  original_images/1949.jpg                                    98  OK \n",
      "Extracting  original_images/1950.jpg                                    98  OK \n",
      "Extracting  original_images/1951.jpg                                    98  OK \n",
      "Extracting  original_images/1952.jpg                                    98  OK \n",
      "Extracting  original_images/1953.jpg                                    98  OK \n",
      "Extracting  original_images/1954.jpg                                    98  OK \n",
      "Extracting  original_images/1955.jpg                                    98  OK \n",
      "Extracting  original_images/1956.jpg                                    98  OK \n",
      "Extracting  original_images/1957.jpg                                    98  OK \n",
      "Extracting  original_images/1958.jpg                                    98  OK \n",
      "Extracting  original_images/1959.jpg                                    98  OK \n",
      "Extracting  original_images/1960.jpg                                    98  OK \n",
      "Extracting  original_images/1961.jpg                                    98  OK \n",
      "Extracting  original_images/1962.jpg                                    98  OK \n",
      "Extracting  original_images/1963.jpg                                    98  OK \n",
      "Extracting  original_images/1964.jpg                                    98  OK \n",
      "Extracting  original_images/1965.jpg                                    98  OK \n",
      "Extracting  original_images/1966.jpg                                    98  OK \n",
      "Extracting  original_images/1967.jpg                                    98  OK \n",
      "Extracting  original_images/1968.jpg                                    98  OK \n",
      "Extracting  original_images/1969.jpg                                    98  OK \n",
      "Extracting  original_images/1970.jpg                                    98  OK \n",
      "Extracting  original_images/1971.jpg                                    98  OK \n",
      "Extracting  original_images/1972.jpg                                    98  OK \n",
      "Extracting  original_images/1973.jpg                                    98  OK \n",
      "Extracting  original_images/1974.jpg                                    98  OK \n",
      "Extracting  original_images/1975.jpg                                    99  OK \n",
      "Extracting  original_images/1976.jpg                                    99  OK \n",
      "Extracting  original_images/1977.jpg                                    99  OK \n",
      "Extracting  original_images/1978.jpg                                    99  OK \n",
      "Extracting  original_images/1979.jpg                                    99  OK \n",
      "Extracting  original_images/1980.jpg                                    99  OK \n",
      "Extracting  original_images/1981.jpg                                    99  OK \n",
      "Extracting  original_images/1982.jpg                                    99  OK \n",
      "Extracting  original_images/1983.jpg                                    99  OK \n",
      "Extracting  original_images/1984.jpg                                    99  OK \n",
      "Extracting  original_images/1985.jpg                                    99  OK \n",
      "Extracting  original_images/1986.jpg                                    99  OK \n",
      "Extracting  original_images/1987.jpg                                    99  OK \n",
      "Extracting  original_images/1988.jpg                                    99  OK \n",
      "Extracting  original_images/1989.jpg                                    99  OK \n",
      "Extracting  original_images/1990.jpg                                    99  OK \n",
      "Extracting  original_images/1991.jpg                                    99  OK \n",
      "Extracting  original_images/1992.jpg                                    99  OK \n",
      "Extracting  original_images/1993.jpg                                    99  OK \n",
      "Extracting  original_images/1994.jpg                                    99  OK \n",
      "Extracting  original_images/1995.jpg                                    99  OK \n",
      "Extracting  original_images/1996.jpg                                    99  OK \n",
      "Extracting  original_images/1997.jpg                                    99  OK \n",
      "Extracting  original_images/1998.jpg                                    99  OK \n",
      "Extracting  original_images/1999.jpg                                    99  OK \n",
      "Extracting  original_images/2000.jpg                                    99  OK \n",
      "Extracting  original_images/1.jpg                                       99  OK \n",
      "Extracting  original_images/10.jpg                                      99  OK \n",
      "Extracting  original_images/100.jpg                                     99  OK \n",
      "Extracting  original_images/101.jpg                                     99  OK \n",
      "All OK\n",
      "\n",
      "UNRAR 5.30 beta 2 freeware      Copyright (c) 1993-2015 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from processed.rar\n",
      "\n",
      "Extracting  miml data.mat                                                 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 99  OK \n",
      "All OK\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.lamda.nju.edu.cn/files/miml-image-data.rar\n",
    "!unrar e miml-image-data.rar # gives two rar files\n",
    "!mkdir -p original_images\n",
    "!unrar e original.rar original_images\n",
    "!unrar e processed.rar  # produces miml data.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "From the PyTorch framework, we import the necessary classes: neural net (nn) models to train the classifier on, optimizers to update the model paramters, image transforms to resize and normalize the images, and metrics generators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import models, transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat  # Load MATLAB file.\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the PyTorch and torchvision version to ensure that they meet our expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch version: 1.7.1\ntorchvision version: 0.8.2\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'torchvision version: {torchvision.__version__}')"
   ]
  },
  {
   "source": [
    "# Dataset Processing\n",
    "Our SceneDataset class inherits from `Dataset` and overrides the following methods (this is typical way to subclass this class) :\n",
    "\n",
    "•\t`__len__` to support returning the size of the Dataset instance.\n",
    "\n",
    "•\t`__getitem__` to support indexing such that the ith sample of an instance of SceneDataset can be retrieved.\n",
    " \n",
    "To the class, we add a `get_labels` method to get the labels associated with an image at index.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SceneDataset(Dataset):\n",
    "    \"\"\" Subclass from Dataset and overide __get_item__ for data-specific indexing\n",
    "     and __len__ to get data-specific length.\n",
    "     We also add a new method, get_labels(index) to avoid going thru an expensive __getitem__\"\"\"\n",
    "     \n",
    "    def __init__(self, df, transforms=None):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def get_labels(self, idx):\n",
    "        record = self.df.iloc[idx]\n",
    "        return record[1:].tolist()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        record = self.df.iloc[idx]\n",
    "        image = Image.open(record['filename']).convert(\"RGB\")\n",
    "        label = torch.tensor(record[1:].tolist(), dtype=torch.float32)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We take a stock ResNet50 model with all the pretrained weights and apply a few changes to the model. First, we create a new head (see method `_create_head`) that consists of three Linear layers.\n",
    "The new head layers can be sumamrized as:\n",
    "```\n",
    "(fc): Sequential(\n",
    "      (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
    "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (2): ReLU()\n",
    "      (3): Dropout(p=0.3, inplace=False)\n",
    "      (4): Linear(in_features=1024, out_features=512, bias=True)\n",
    "      (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (6): ReLU()\n",
    "      (7): Dropout(p=0.3, inplace=False)\n",
    "      (8): Linear(in_features=512, out_features=5, bias=True)\n",
    "    )\n",
    "```\n",
    "We then replace the last fully connected layer with the new head. A conceptual diagram of the final network (`ExtendedResNetModel`) is shown below.\n",
    "\n",
    "![resnet with head](assets/new-rn50-head.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedResNetModel(nn.Module):\n",
    "    \"\"\" Extend ResNet with three new fully connected layers and attach them as a head to a ResNet50 trunk\"\"\"\n",
    "\n",
    "    def __init__(self, nb_classes, dropout_prob=0.3, activation_func=nn.ReLU):\n",
    "        super().__init__()\n",
    "        # load the pretrained model as feafures\n",
    "        self.rn50_features = models.resnet50(pretrained=True)\n",
    "        # get the nb of in_features in last Linear unit\n",
    "        nb_in_features_last = self.rn50_features.fc.in_features\n",
    "        for param in self.rn50_features.parameters():\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "        head = self._create_head(nb_in_features_last, nb_classes,\n",
    "                                 dropout_prob, activation_func)\n",
    "        self.rn50_features.fc = head  # attach head\n",
    "        # print(self.rn50_features)\n",
    "\n",
    "    def _create_head(self, nb_features, nb_classes, dropout_prob=0.3, activation_func=nn.ReLU):\n",
    "        features_lst = [nb_features, nb_features//2, nb_features//4]\n",
    "        layers = []\n",
    "        for in_f, out_f in zip(features_lst[:-1], features_lst[1:]):\n",
    "            layers.append(nn.Linear(in_f, out_f))\n",
    "            layers.append(nn.BatchNorm1d(out_f))\n",
    "            layers.append(activation_func())\n",
    "            if dropout_prob != 0:\n",
    "                layers.append(nn.Dropout(dropout_prob))\n",
    "        layers.append(nn.Linear(features_lst[-1], nb_classes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.rn50_features(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, scheduler, nb_epochs=5):\n",
    "\n",
    "    for epoch in range(nb_epochs):\n",
    "        result = []\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == \"train\":  \n",
    "                model.train()  # put model in training mode\n",
    "            else:  \n",
    "                model.eval()  # # put model in validation mode\n",
    "\n",
    "            # Track for each epoch\n",
    "            running_loss = 0.0\n",
    "            running_f1_score = 0.0\n",
    "            running_roc_auc_score = 0.0\n",
    "\n",
    "            for data, targets in data_loader[phase]:\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(data)  # forward pass\n",
    "                    loss = criterion(outputs, targets)\n",
    "                    preds = outputs.data > 0.5\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()  # compute gradient of the loss with respect to model parameters\n",
    "                        optimizer.step()  # update the model parameters\n",
    "                        scheduler.step()\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                running_loss += loss.item() * len(data)\n",
    "                running_f1_score += f1_score(targets.to(\"cpu\").to(torch.int).numpy(),\n",
    "                                             preds.to(\"cpu\").to(torch.int).numpy(),\n",
    "                                             average=\"samples\") * len(data)\n",
    "                running_roc_auc_score += roc_auc_score(targets.to(\"cpu\").to(torch.int).numpy(),\n",
    "                                                       preds.to(\"cpu\").to(torch.int).numpy(),\n",
    "                                                       average=\"samples\") * len(data)\n",
    "\n",
    "            epoch_loss = running_loss / len(data_loader[phase].dataset)\n",
    "            epoch_f1_score = running_f1_score / len(data_loader[phase].dataset)\n",
    "            epoch_roc_auc_score = running_roc_auc_score / \\\n",
    "                len(data_loader[phase].dataset)\n",
    "\n",
    "            result.append(f'Epoch:{epoch} {phase.upper()}: Loss:{epoch_loss:.4f} '\n",
    "                          f'F1-Score: {epoch_f1_score:.4f} AUC: {epoch_roc_auc_score:.4f}')\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "class labels: ['desert', 'mountains', 'sea', 'sunset', 'trees']\n"
     ]
    }
   ],
   "source": [
    "# To download the dataset, see accompanying file, dataset_download_steps.txt.\n",
    "dataset_root = '.'\n",
    "\n",
    "# Read the \"processed\" part for class names and class labels\n",
    "processed_mat = loadmat(os.path.join(dataset_root, 'miml data.mat'))\n",
    "class_labels = []\n",
    "for c in processed_mat['class_name']:  # get the name of each class\n",
    "    class_labels.append(c[0][0])\n",
    "nb_classes = len(class_labels)\n",
    "print('class labels:', class_labels)  # ['desert', 'mountains', 'sea', 'sunset', 'trees']\n",
    "\n",
    "# Read the labels. If multi-class label for ith images equals [1, -1, -1, 1, -1], it means:\n",
    "# i-th image belongs to the 1st & 4th class but does not belong to the 2nd, 3rd &  5th classes\n",
    "labels = copy.deepcopy(processed_mat['targets'].T)\n",
    "labels[labels == -1] = 0  # convert to range [0, 1] from [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a pandas dataframe with file location and associated (multi) labels as below\n",
    "#                   filename desert mountains sea sunset trees\n",
    "# 0  ./original_images/1.jpg      1         0   0      0     0\n",
    "# 1  ./original_images/2.jpg      1         0   0      0     0\n",
    "# 2  ./original_images/3.jpg      1         0   0      0     0\n",
    "# 3  ./original_images/4.jpg      1         1   0      0     0\n",
    "# 4  ./original_images/5.jpg      1         0   0      0     0\n",
    "\n",
    "# create empty dataframe with columns, [filename desert mountains sea sunset tree]\n",
    "data_df = pd.DataFrame(columns=['filename'] + class_labels)\n",
    "filenames = os.listdir(os.path.join(dataset_root, \"original_images/\"))\n",
    "data_df['filename'] = np.array(\n",
    "    sorted(list(map(lambda x: int(Path(x).stem), np.array(filenames)))))\n",
    "data_df['filename'] = data_df['filename'].apply(\n",
    "    lambda x: os.path.join(dataset_root, 'original_images/') + str(x) + '.jpg')\n",
    "data_df[class_labels] = np.array(labels)\n",
    "\n",
    "transforms_list = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                      std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set size: 1400; Val set size: 600\n",
      "Ratio of Negative samples to positive samples per class: tensor([4.0909, 3.5161, 2.3981, 3.2424, 2.5088], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.3\n",
    "dataset = SceneDataset(data_df, transforms_list)\n",
    "split_point = int(len(dataset) * split_ratio)\n",
    "trainset, valset = random_split(\n",
    "    dataset, [len(dataset) - split_point, split_point], generator=torch.Generator().manual_seed(0))\n",
    "print(f\"Train set size: {len(trainset)}; Val set size: {len(valset)}\")\n",
    "\n",
    "batch_size = 128\n",
    "dataloader = {\"train\": DataLoader(trainset, shuffle=True, batch_size=batch_size),\n",
    "              \"val\": DataLoader(valset, shuffle=True, batch_size=batch_size)}\n",
    "\n",
    "positive_weights = []\n",
    "for cls in range(nb_classes):\n",
    "    positive_samples = float(sum([dataset.get_labels(idx)[cls] == 1 for idx in trainset.indices]))\n",
    "    negative_samples = float(sum([dataset.get_labels(idx)[cls] == 0 for idx in trainset.indices]))\n",
    "    pos_weight = negative_samples / positive_samples\n",
    "    positive_weights.append(pos_weight)\n",
    "positive_weights = torch.FloatTensor(positive_weights).to('cuda')\n",
    "print('Ratio of Negative samples to positive samples per class:', positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Epoch:0 TRAIN: Loss:0.5277 F1-Score: 0.7289 AUC: 0.8444', 'Epoch:0 VAL: Loss:0.5010 F1-Score: 0.8118 AUC: 0.8901']\n",
      "['Epoch:1 TRAIN: Loss:0.2617 F1-Score: 0.8901 AUC: 0.9371', 'Epoch:1 VAL: Loss:0.4053 F1-Score: 0.8393 AUC: 0.9073']\n",
      "['Epoch:2 TRAIN: Loss:0.1828 F1-Score: 0.9283 AUC: 0.9586', 'Epoch:2 VAL: Loss:0.3926 F1-Score: 0.8519 AUC: 0.9138']\n",
      "['Epoch:3 TRAIN: Loss:0.1162 F1-Score: 0.9577 AUC: 0.9782', 'Epoch:3 VAL: Loss:0.3444 F1-Score: 0.8694 AUC: 0.9224']\n",
      "['Epoch:4 TRAIN: Loss:0.0857 F1-Score: 0.9688 AUC: 0.9817', 'Epoch:4 VAL: Loss:0.4510 F1-Score: 0.8208 AUC: 0.8928']\n",
      "['Epoch:5 TRAIN: Loss:0.0740 F1-Score: 0.9740 AUC: 0.9869', 'Epoch:5 VAL: Loss:0.5443 F1-Score: 0.8249 AUC: 0.8953']\n",
      "['Epoch:6 TRAIN: Loss:0.0542 F1-Score: 0.9827 AUC: 0.9900', 'Epoch:6 VAL: Loss:0.7529 F1-Score: 0.7750 AUC: 0.8629']\n",
      "['Epoch:7 TRAIN: Loss:0.0422 F1-Score: 0.9847 AUC: 0.9920', 'Epoch:7 VAL: Loss:0.7464 F1-Score: 0.7943 AUC: 0.8776']\n",
      "['Epoch:8 TRAIN: Loss:0.0363 F1-Score: 0.9912 AUC: 0.9948', 'Epoch:8 VAL: Loss:0.5550 F1-Score: 0.8203 AUC: 0.8886']\n",
      "['Epoch:9 TRAIN: Loss:0.0295 F1-Score: 0.9910 AUC: 0.9954', 'Epoch:9 VAL: Loss:0.5698 F1-Score: 0.8450 AUC: 0.9060']\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = ExtendedResNetModel(nb_classes=nb_classes)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=positive_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "sgdr_cos_anneal_sched = lr_scheduler.CosineAnnealingLR(optimizer,  # set learning rate schedule\n",
    "                                                 T_max=5, eta_min=0.005)\n",
    "\n",
    "train(model, dataloader, criterion, optimizer, sgdr_cos_anneal_sched, nb_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('pyt1.2': conda)",
   "language": "python",
   "name": "python38264bitpyt12condaa6d578b60c2b45e7882cc9b9680228e7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}